import numpy as np
import cv2
import math
import time

def get_features(image, x, y, feature_width):
    time_start = time.time()
    '''
    Task:
        -> Returns a set of feature descriptors for a given set of interest points.
    param:
        -> image: a grayscale or color image
        -> x: np array of x coordinates of interest points
        -> y: np array of y coordinates of interest points
        -> feature_width: in pixels, is the local feature width. You can assume
                        that feature_width will be a multiple of 4 (i.e. every cell of your
                        local SIFT-like feature will have an integer width and height).
    :returns:
        -> fv:normalized feature vector
    '''
    # Round off the x and y coordinates to integers.
    x = np.rint(x)
    x = x.astype(int)
    y = np.rint(y)
    y = y.astype(int)
    # Define a gaussian filter.
    cutoff_frequency = 10
    filter1 = cv2.getGaussianKernel(ksize=4, sigma=cutoff_frequency)
    filter1 = np.dot(filter1, filter1.T)
    # Apply the gaussian filter to the image.
    image = cv2.filter2D(image, -1, filter1)
    ImageRows = image.shape[0]
    ImageColumns = image.shape[1]
    Xcoordinates = len(x)
    Ycoordinates = len(y)
    FeatureVectorIn = np.ones((Xcoordinates, 128))
    NormalizedFeature = np.zeros((Xcoordinates, 128))
    # loop over the corners generated by Harris
    for i in range(Xcoordinates):
        # Extract a 16X16 window centered at the corner pixel
        temp1 = int(x[i])
        temp2 = int(y[i])
        Window = image[temp2-8:temp2 + 8, temp1-8:temp1 + 8]
        WindowRows = Window.shape[0]
        WindowColumns = Window.shape[1]
        # loop over 16 4X4 windows and compute the magnitude and orientation of each pixel
        for p in range(4):
            for q in range(4):
                WindowCut = Window[p*4:p*4+4, q*4: q*4+4]       # one 16x16 window --> sixteen 4x4 window
                NewWindowCut = cv2.copyMakeBorder(WindowCut, 1, 1, 1, 1, cv2.BORDER_REFLECT)
                Magnitude = np.zeros((4, 4))
                Orientation = np.zeros((4, 4))          # direction
                for r in range(WindowCut.shape[0]):     # Traverse WindowCut to calculate the magnitude and orientation
                    for s in range(WindowCut.shape[1]):
                        Magnitude[r, s] = math.sqrt((NewWindowCut[r+1, s] - NewWindowCut[r-1, s])**2 +
                                                    (NewWindowCut[r, s+1] - NewWindowCut[r, s-1])**2)
                        Orientation[r, s] = np.arctan2((NewWindowCut[r+1, s] - NewWindowCut[r-1, s]),
                                                       (NewWindowCut[r, s+1] - NewWindowCut[r, s-1]))
                # put the generated orientation values to a histogram with the weights being the corresponding magnitude values
                Magnitude = Magnitude
                OrientationNew = Orientation*(180/(math.pi))
                hist, edges = np.histogram(OrientationNew, bins=8, range=(-180, 180), weights=Magnitude)
                for t in range(8):
                    l = t+p*32+q*8
                    FeatureVectorIn[i, l] = hist[t]

    # Normalize the generated feature vector
    for a in range(FeatureVectorIn.shape[0]):
        sum1 = 0
        for b in range(FeatureVectorIn.shape[1]):
            sum1 = sum1 + (FeatureVectorIn[a][b])*(FeatureVectorIn[a][b])
        sum1 = math.sqrt(sum1)
        for c in range(FeatureVectorIn.shape[1]):
            NormalizedFeature[a][c] = FeatureVectorIn[a][c]/sum1
    # Return normalized feature vector
    fv = NormalizedFeature

    time_end = time.time()
    print('get_features cost:', time_end - time_start)
    return fv
